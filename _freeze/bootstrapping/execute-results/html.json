{
  "hash": "3f0c80570162428b4a26a4fbe953f0f8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The Bootstrap Method\"\ndate-modified: \"2024-10-16\"\n---\n\n\n\n\nThe Boostrap Method is an approach that can construct the sampling distribution of several estimators, not all estimators, without imposing a mathematical model on the data. The idea is that the sample $X_1, \\ldots, X_n$ is generated from a distribution function called $F(\\theta)$. If the sample is large enough, then the empirical distribution function $\\hat F_n$ should begin to look like the true distribution function $F$. This implies that the sample contains all the information of $F$. Therefore, if we resample from our sample, with replacement, we are then sampling from our empirical distribution $\\hat F_n$, which looks really close to the true distribution function $F$.\n\n**R Packages Used**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nlibrary(tidyverse)\ntheme_set(theme_bw())\ntheme_update(axis.title = element_text(size = 24))\n```\n:::\n\n\n\n\n## Empirical Distribution Function\n\nThe empirical distribution function is designed to estimate a random variable's distribution function. For an observed sample $\\{x_i\\}^n_{i=1}$, the empirical distribution function is\n\n$$\n\\hat F_n(x) = \\left\\{\\begin{array}{cc}\n0, & x < x_{(1)} \\\\\n\\frac{i}{n},& x_{(i)} \\leq x <x_{(i+1)},\\ i = 1,\\ldots,n-1\\\\\n1,& x_{(n)}\\leq x\n\\end{array}\n\\right.\n$$\n\nwhere $x_{(1)}, \\ldots, x_{(n)}$ is the ordered sample. Looking at the Glivenko-Cantelli Theorem, the empirical distribution function converges to the true function as $n\\rightarrow \\infty$. For a large enough sample, $\\hat F_n$ will contain the same information as $F$.\n\n\n::: callout-note\n### Glivenko-Cantelli Theorem\n\nIf random variables $X_1, X_2, \\cdots, X_n$ are independent come from the same distribution ($iid$), then\n\n$$\n\\hat F_n (x) \\rightarrow F(x)\n$$\n\nconverges uniformly as $n\\rightarrow \\infty$, for more information click [here](https://en.wikipedia.org/wiki/Glivenko%E2%80%93Cantelli_theorem).\n\n:::\n\n\n\nAccordingly, the sample generated has it's own distribution function called $\\hat F_n$ where the probability of seeing any value $x_i$ is $1/n$. Therefore, if we were to resample $\\{x_i\\}^n_{i=1}$, with replacement, it is equivalent to sampling from $\\hat F_n$. \n\n## The Bootstrap Method\n\nThe Bootstrap Method is commonly used to obtain the standard error and or confidence limits of an estimator. By repeatedly sampling from $\\hat F_n$, the sampling distribution of any estimator can be approximated. This is advantageous from standard mathematical models which imposes a distribution on $F$, which may be completely inaccurate. The only assumption being made is that $\\hat F_n$ is close the true distribution function $F$.  \n\n### Algorithm\n\nLet $\\boldsymbol X = (X_1, X_2, \\ldots, X_n)$ be a random sample from a distribution $F$. For an estimator $T(\\cdot)$: \n\n1.  Draw a sample $\\boldsymbol X^*_b$ of size $n$, with replacement, from the original data $\\boldsymbol X$.\n2.  Compute the bootstrap replicate statistic $T*_b = T(\\boldsymbol X^*_b)$, where $T(\\cdot)$ is the function that computes the statistic of interest.\n3.  Repeat steps 1-2 $B$ times to obtain $B$ bootstrap replicates $T^*{T*_1, T*_2, ..., T*_B}$.\n\n\nThe computed statistics from $B$ samples are the empirical bootstrap distribution of the estimator, $T(\\boldsymbol X)$. This can be used to compute the standard error, bias, and confidence interval of the estimator $T(\\boldsymbol X)$. The number or replicates needed is open to discussion; however, research has shown $B=200$ to suffiece. Larger $B$ may be needed for confidence limit estimation. Another rule of thumb is having $B=n$; however, this may be unfeasible for extremely large samples or computationally intensive tasks.\n\n### Standard Error Estimation\n\nThe bootstrap-based standard error of an estimator is shown to provide an unbiased estimate of the true standard error. We can compute the standard eror using the following formula:\n\n$$\n\\hat{se}\\left\\{T(\\boldsymbol X)\\right\\} = \\sqrt{\\frac{1}{B-1}\\sum^B_{i=1}(T^*_i-\\bar T^*)^2}\n$$\nwhere $\\bar T^* = \\frac{1}{B}\\sum^B_{i=1}T^*_i$.\n\n\n### Bias Estimation\n\nThe bootstrap-based bias estimate can be computed by the following formula:\n\n$$\n\\widehat{bias}\\left\\{T(\\boldsymbol X)\\right\\} = \\bar T^* -  T(X)\n$$\n\nwhere $\\bar T^* = \\frac{1}{B}\\sum^B_{i=1}T^*_i$ is the mean estimate of the bootstrap samples and $T(X)$ is computed statistic from the data.\n\n### Confidence Limits Estimation\n\nThe confidence limits of a parameter can be estimated by using the percentiles of the bootstrap replicates. The $(1-\\alpha) 100 \\%$ bootstrap confidence interval can be represented as:\n\n$$\n(T^*_{\\alpha/2},\\ T^*_{1-\\alpha/2})\n$$\nwhere $T^*_{\\alpha/2}$ with $\\alpha/2$ quantile and $T^*_{1-\\alpha/2}$ quantile of the bootstrap replicates.\n\n\n### Limitation to Boostrap Methods\n\nLet's say we randomly sample 5 data points from a Poisson Distribution with a rate of 5^[Note: The `set.seed` function ensures that the same random sample will be generated.]:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nx <- rpois(5, 1.5)\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 3 4 1 3 2\n```\n\n\n:::\n:::\n\n\n\n\nIf we were to use this sample and generate bootstrap estimates, we will obtain inaccurate results. This is because the empirical distribution function is a poor estimate of the true distribution function. One reason being that the $P(X = 0) = 0.2231$, and our sample does not have any 0 values. Any bootstrap samples produced will never carry that information. This is why a large sample is needed so the sample space can be thoroughly explored.\n\n## Examples\n\nThe examples below illustrate how to compute the bootstrap standard errors and confidence limits in a regression setting.\n\n### Linear Regression\n\nThe `mtcars` data set contains information on cars from 1974 *Motor Trend* US Magazine. Fitting a linear regression model between the variable `mpg` and `wt`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(mpg ~ wt, mtcars) |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = mpg ~ wt, data = mtcars)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -4.5432 -2.3647 -0.1252  1.4096  6.8727 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  37.2851     1.8776  19.858  < 2e-16 ***\n#> wt           -5.3445     0.5591  -9.559 1.29e-10 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 3.046 on 30 degrees of freedom\n#> Multiple R-squared:  0.7528,\tAdjusted R-squared:  0.7446 \n#> F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n```\n\n\n:::\n\n```{.r .cell-code}\nlm(mpg ~ wt, mtcars) |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                 2.5 %    97.5 %\n#> (Intercept) 33.450500 41.119753\n#> wt          -6.486308 -4.202635\n```\n\n\n:::\n:::\n\n\n\nWe can see that the estimated model between the 2 variables is $\\widehat{mpg} = 37.285 - 5.345 wt$. The standard error, based on the normal distribution, for the coefficient of `wt` is 0.5591. The 95% confidence interval for the coefficient of `wt` is (-6.486, -4.203)^[Note: The residual analysis may suggest that the linear regression model is not appropriate.].\n\nTo obtain the bootstrap-based standard error and 95% confidence interval, we will need to sample data points in the data set, with replacement. The user created function below will sample data points with replacement^[Note: You will need to have the `dplyr` function installed.]:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresample <- function(df){\n  dplyr::slice_sample(df, n = nrow(df), replace = T )\n}\n```\n:::\n\n\n\n\nUsing the `resample`, we can get a bootstrap sample:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb1 <- resample(mtcars)\nb1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                          mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n#> Hornet 4 Drive...1      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#> Fiat 128...2            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n#> Fiat X1-9...3           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#> Chrysler Imperial       14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n#> Volvo 142E              21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n#> Cadillac Fleetwood...6  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n#> Camaro Z28              13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n#> Duster 360              14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n#> Hornet 4 Drive...9      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#> Pontiac Firebird...10   19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n#> Hornet Sportabout...11  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#> Merc 450SLC             15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n#> Toyota Corolla...13     33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n#> Fiat X1-9...14          27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#> Fiat 128...15           32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n#> Cadillac Fleetwood...16 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n#> Datsun 710...17         22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n#> Merc 230                22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n#> Pontiac Firebird...19   19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n#> Porsche 914-2           26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n#> Hornet 4 Drive...21     21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#> Hornet Sportabout...22  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#> Maserati Bora           15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n#> Merc 450SL              17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n#> Hornet Sportabout...25  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#> Toyota Corolla...26     33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n#> Mazda RX4 Wag           21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n#> Lotus Europa            30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n#> Merc 240D               24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n#> Datsun 710...30         22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n#> Fiat X1-9...31          27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#> Mazda RX4               21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n```\n\n\n:::\n:::\n\n\n\n\nNotice that some data points are repeated. We will then construct 10,000 bootstrap samples:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboots <- lapply(1:10000, \\(x) resample(mtcars))\n```\n:::\n\n\n\n\nThe object `boots` is a list, with each element contain a boot replicate data set. Now we will, apply the `lm` function for each data set in `boots`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboots_lm <- lapply(boots, \\(x) lm(mpg ~ wt, x))\n```\n:::\n\n\n\n\nLastly, we will extract the coefficient value for each replicate^[We will unlist the object to utilize a vector]:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboots_wt <- lapply(boots_lm, \\(x) coef(x)[\"wt\"]) |> unlist()\n```\n:::\n\n\n\n\nLet's visualize the distribution for the coefficient of `wt`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(x = boots_wt) |> \n  ggplot(aes(x)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](bootstrapping_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nThe plot indicate that the coefficient for `wt` may not be symmetrical. The standard error can be obtained by applying the `sd` function to `boots_wt`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd(boots_wt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.7046252\n```\n\n\n:::\n:::\n\n\n\n\nThe bootstrap-based standard error is 0.71. This is different from the normal-based standard error of 0.55. The 95% confidence interval of the coefficient of `wt` cna be obtained by using the `quantile` function and setting `probs = c(0.025, 0.975)`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(boots_wt, probs = c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>      2.5%     97.5% \n#> -6.953420 -4.130759\n```\n\n\n:::\n:::\n\n\n\n\nThe bootstrap-based 95% confidence interval is (-6.973, -4.164), which is slightly wider than the mathematical-based 95% confidence interval: (-6.486, -4.203).",
    "supporting": [
      "bootstrapping_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}