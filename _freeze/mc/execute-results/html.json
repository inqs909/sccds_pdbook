{
  "hash": "e55e1a915a5fd54159ad309aa120e8fd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Monte Carlo Methods\"\ndate-modified: \"2025-03-23\"\n---\n\n\n\n\n## R Setup\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(patchwork)\n\ntheme_set(theme_bw())\n```\n:::\n\n\n\n\n\n## Distributions in R\n\nSeveral common distributions can be utilized in R with the 4 common functions:\n\n| Letter | Functionality                                                 |\n|:-------|:--------------------------------------------------------------|\n| `d`    | returns the height of the probability density/mass function   |\n| `p`    | returns the cumulative density function value                 |\n| `q`    | returns the inverse cumulative density function (percentiles) |\n| `r`    | returns a randomly generated number                           |\n\n\n## Random Number Generator\n\n## Generating Random Numbers\n\nA number is an outcome from a random experiment.\n\n\nRandom experiment is an experiment where the outcome is not predicted.\nThe outcomes have a probability of being observed, whether equal or not.\n\n\n### Psuedo Random Numbers\n\nThese methods are considered time-consuming when a large number values are necessary.\n\nWith the advent of computers, random number can be generated with the use deterministic algorithms, where a mechanism is used to make it random, such as time.\nComputer-generated random numbers are considered psuedo random numbers because an algorithm is used to generate them given an initial single value, known as a seed.\n\nSupplying a seed to a random number generator will ensure that the same numbers are produced every time.\n\n### Mersenne Twister\n\nThe Mersenne Twister is a widely used pseudorandom number generator (PRNG) known for its high quality and efficiency. It was developed by Makoto Matsumoto and Takuji Nishimura in 1997. \n\nThe default random number generator in R.\n\n\n## Uniform Distribution R\n\n::: {.panel-tabset}\n\n### Description\n\nThe `runif` function in R will generate a value the come from a uniform distribution.\n\n`runif` arguments:\n\n-   `n`: number of values to generate\n-   `min`: the smallest possible value to generate\n-   `max`: the largest possible value to generate\n\n### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrunif(1, 0, 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.8797699\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n\n## Random Variable Generations\n\n### Random Variable Generation\n\nSeveral distribution, common and uncommon, can be generated using a uniform random variables.\n\n\nMore complex distributions may require the use of common distributions.\n\n### Inverse-Transform Method\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- -20\nb <- 4\nx <- seq(a, b, length.out = 1000)\npnorm(x, -8, sqrt(10)) |> tibble(x = x, y = _) |> \nggplot(aes(x,y)) +\ngeom_line() +\ntheme_bw() +\nggtitle(\"CDF\") +\nylab(paste0(\"P(X\",\"\\u2264\",\" x)\"))\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n### Inverse-Transformation Algorithm \n\n1.    Generate a random value $U$ that follows a $U(0,1)$\n2.    Using the CDF ($F(X)$) for random variable $X$, compute:\n\n$$\nX = F^{-1}(U)\n$$\n\n\n### Exponential Distribution\n\nAn exponential random variable is characterized by the exponential distribution, used to model waiting times or the time until an event occurs a certain number of times.\n\nThe exponential distribution is a gamma random variable with $\\alpha = 1$.\n\n### Exponential Distribution\n\n$$\nf(x) = \\frac{1}{\\lambda} \\exp\\left\\{-\\frac{x}{\\lambda}\\right\\}\n$$\n\n$$\nF(x) = 1-\\exp\\left\\{-\\frac{x}{\\lambda}\\right\\}\n$$\n\n$$\nF^{-1}(x) = -\\lambda \\log(1-x)\n$$\n\n### Simulating an Exponential RV\n\n$$\nX \\sim Exp(2)\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxe <- seq(0, 4, length.out = 1000)\nu <- runif(100000)\nu |> tibble(x = _) |> \nggplot(aes(x=u, y = ..density..)) +\ngeom_histogram() +\ngeom_line(data = tibble(x = xe, y = dexp(xe, rate = 1/2)),\n          mapping = aes(x,y)) +\ntheme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#> â„¹ Please use `after_stat(density)` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n### Simulating an Exponential RV\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nu <- runif(100000)\nx <- -2 * log(1-u)\n```\n:::\n\n\n\n\n### Simulating an Exponential RV\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx |> tibble(x = _) |> \nggplot(aes(x=x, y = ..density..)) +\ngeom_histogram() +\ngeom_line(data = tibble(x = xe, y = dexp(xe, rate = 1/2)),\n          mapping = aes(x,y)) +\ntheme_bw()\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Exponential RV in R\n\n::: {.panel-tabset}\n### Description\n\nThe exponential distribution can be simulated in R using the `rexp` function with the following arguments:\n\n-   `n`: number of values to generate\n-   `rate`: how fast would events occur\n\n### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrexp(1, rate = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.4089772\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n### Discrete RV Inverse-Transformations\n\n1.    Generate a random value $U$ that follows a $U(0,1)$\n2.    Using the CDF ($F(X)$), find the smallest integer value $k$ such that:\n\n$$\nU \\leq F(k)\n$$\n3.    $X \\leftarrow k$\n\n### Poisson Distribution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxe <- 0:20\nu <- runif(100000)\nu |> tibble(x = _) |> \nggplot(aes(x=x, y = ..density..)) +\ngeom_histogram(bins = 20) +\ngeom_step(data = tibble(x = xe, y = dpois(xe, lambda = 6)),\n          mapping = aes(x,y)) +\ntheme_bw()\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n### Poisson Distribution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nfinder <- function(u){\n  x <- 0\n  condition <- TRUE\n  while (condition) {\n    uu <- ppois(x, lambda = 6)\n    condition <- uu <= u\n    if(condition){\n      x <- x + 1\n    }\n  }\n  return(x)\n}\nxx <- sapply(u, finder)  \nxx |> tibble(x = _) |> \nggplot(aes(x=x, y = ..density..)) +\ngeom_histogram(bins = 21) +\ngeom_step(data = tibble(x = xe, y = dpois(xe, lambda = 6)),\n          mapping = aes(x,y)) +\ntheme_bw()\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n### Exponential RV in R\n\n::: {.panel-tabset}\n### Description\n\nThe Poisson distribution can be simulated in R using the `rpois` function with the following arguments:\n\n-   `n`: number of values to generate\n-   `lambda`: the average expected event\n\n### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrpois(1, lambda = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 2\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n### Normal Distribution\n\nObtaining the inverse distribution function of a normal distribution requires the use of numeric algorithms.\n\n\nTherefore it is computationally inefficient to use the inverse-transformation algorithm to generate normal random variables.\nThe Box-Muller algorithm was developed to generate 2 standard normal ($N(0,1)$) random variables from uniform random variables.\n\n### Normal Distribution\n\n$$\ny = \\int^x_{-\\infty} \n\\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{-\\frac{z^2}{2}\\right\\}dz\n$$\n\n### Box-Muller Algorithm\n\n1. Generate 2 independent random variables from $U(0,1)$, $U_1$ and $U_2$\n2. $X_1 = (-2 \\log(U_1))^{1/2}\\cos(2\\pi U_2)$\n3. $X_2 = (-2 \\log(U_1))^{1/2}\\sin(2\\pi U_2)$\n\nBoth $X_1$ and $X_2$ are independent $N(0,1)$\n\n### Normal Distribution R\n\n::: {.panel-tabset}\n\n### Description\n\nThe normal distribution can be simulated in R using the `rnorm` function with the following arguments:\n\n-   `n`: number of values to generate\n-   `mean`: the central tendency (peak)\n-   `sd`: the variation of the data (width)\n\n### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrnorm(1, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] -1.115184\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n\n## Accept-Reject Algorithm\n\nThe Accept-Reject algorithm allows you to generate noncommon random variable by simulating from a common random variable.\n\n### Algorithm Set Up\n\nLet $X$ be the random variable, that is difficult to generate, you want to generate with a pdf $f(x)$. \n\nLet $Y$ be an easily generated random variable with a pdf $g(y)$. That follows the same support as $f(x)$ \n\nLastly, multiply $g(y)$ with a constant $c$ such that $f(y)\\leq cg(y)$.\n\n### Algorithm\n\n1. Generate $Y$ with a pdf of $g(y)$\n2. Generate $U$ from $U(0, cg(y))$\n3. Accept-Reject\n  1. Accept: $U\\leq f(y)$; $Y \\rightarrow X$\n  2. Reject: $U>f(y)$; repeat the algorithm\n\n### Modified Algorithm\n\n1. Generate $Y$ with a pdf of $g(y)$\n2. Generate $U$ from $U(0,1)$\n3. Accept-Reject\n  1. Accept: $U\\leq f(y)/(cg(y))$; $Y \\rightarrow X$\n  2. Reject: $U>f(y)/(cg(y))$; repeat the algorithm\n\n\n\n### Gamma Random Variable\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxe <- seq(0, 20, length.out = 1000)\nxe |> tibble(x = _) |> \nggplot(aes(x=x, y = dgamma(x, shape = 2.3, scale = 1.2))) + \ngeom_line() +\nylab(\"Density\") +\ntheme_bw()\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Gamma RV\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxe <- seq(0, 20, length.out = 1000)\nx <- rexp(100000)\nx |> tibble(x = _) |> \nggplot(aes(x=x, y = ..density..)) + \ngeom_histogram(aes(color = \"Exponential\")) +\ngeom_line(data = tibble(x = xe, \n                        y = dgamma(x, shape = 2.3, scale = 1.2)), \n          aes(x,y, color = \"Gamma\")) +\nylab(\"Density\") +\ntheme_bw() +\ntheme(legend.position = \"bottom\",\n      legend.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Gamma RV\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxe <- seq(0, 20, length.out = 1000)\nxe |> tibble(x = _) |> \nggplot(aes(x=x, y = dgamma(x, shape = 2.3, scale = 1.2))) + \ngeom_line(aes(color = \"Gamma\")) +\ngeom_line(data = tibble(x = xe, y = dexp(xe, 1/3)), aes(x,y, color = \"Exponential\")) +\nylab(\"Density\") +\ntheme_bw() +\ntheme(legend.position = \"bottom\",\n      legend.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Accept-Reject Gamma RV\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxe <- seq(0, 20, length.out = 1000)\nxe |> tibble(x = _) |> \nggplot(aes(x=x, y = dgamma(x, shape = 2.3, scale = 1.2))) + \ngeom_line(aes(color = \"Gamma\")) +\ngeom_line(data = tibble(x = xe, y = 1.5*dexp(xe, 1/3)), aes(x,y, color = \"Exponential\")) +\nylab(\"Density\") +\ntheme_bw() +\ntheme(legend.position = \"bottom\",\n      legend.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Accept-Reject Gamma RV\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxe <- seq(0, 20, length.out = 1000)\nxe |> tibble(x = _) |> \nggplot(aes(x=x, y = dgamma(x, shape = 2.3, scale = 1.2))) + \ngeom_line(aes(color = \"Gamma\")) +\ngeom_line(data = tibble(x = xe, y = 3*dexp(xe, 1/3)), aes(x,y, color = \"Exponential\")) +\nylab(\"Density\") +\ntheme_bw() +\ntheme(legend.position = \"bottom\",\n      legend.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Accept-Reject Gamma RV\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nx <- c()\nn <- 0\nwhile(n < 10000){\n  e <- rexp(1, 1/2.3)\n  u <- runif(1)\n  f <- dgamma(e, 2.3, 1/1.2)\n  g <- dexp(e, 1/2.3) * 3\n  if (u < (f/g)){\n    x <- c(x, e)\n    n <- length(x)\n  }\n}\n```\n:::\n\n\n\n\n#### Gamma RV\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx |> tibble(x = _) |> \nggplot(aes(x=x, y = ..density..)) + \ngeom_histogram(aes(color = \"Exponential\")) +\ngeom_line(data = tibble(x = xe, \n                        y = dgamma(x, shape = 2.3, scale = 1.2)), \n          aes(x,y, color = \"Gamma\")) +\nylab(\"Density\") +\ntheme_bw() +\ntheme(legend.position = \"bottom\",\n      legend.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Gamma Distribution R\n\n::: {.panel-tabset}\n#### Description\n\nThe gamma distribution can be simulated in R using the `rgamma` function with the following arguments:\n\n-   `n`: number of values to generate\n-   `shape`: describes the shape of distribution ($\\alpha$)\n-   `scale`: the spread of the data ($\\beta$)\n\n#### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrgamma(1, shape = 1.2, rate = .5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 1.381751\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n### Beta RV in R\n\n::: {.panel-tabset}\n#### Description\n\nThe beta distribution can be simulated in R using the `rbeta` function with the following arguments:\n\n-   `n`: number of values to generate\n-   `shape1`: controls the shape of distribution\n-   `shape2`: controls the shape of distribution\n\n#### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrbeta(1, shape1 = 1.2, shape2 = 6.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.2399345\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n\n### Bernoulli RV in R\n\n::: {.panel-tabset}\n#### Description\n\nThe bernoulli distribution can be simulated in R using the `rbinom` function with the following arguments:\n\n-   `n`: number of values to generate\n-   `size = 1`: will give a bernoulli distribution\n-   `prob`: probability of observing 1 (success)\n\n#### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrbinom(1, prob = .2, size = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n### Binomial RV in R\n\n::: {.panel-tabset}\n#### Description\n\nThe binomial distribution can be simulated in R using the `rbinom` function with the following arguments:\n\n-   `n`: number of values to generate\n-   `size`: how many bernoulli trials to conduct\n-   `prob`: probability of observing 1 (success)\n\n#### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrbinom(1, prob = .5, size = 25)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 11\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n### Negative Binomial RV in R\n\n::: {.panel-tabset}\n#### Description\n\nThe negative binomial distribution can be simulated in R using the `rnbinom` function with the following arguments:\n\n-   `n`: number of values to generate\n-   `size`: number of successful trials\n-   `prob`: probability of observing 1 (success)\n\n#### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrnbinom(1, prob = .6, size = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n## Transformation Methods\n\n### $N(0,1)$\n\n$$\nX \\sim N(\\mu, \\sigma^2)\n$$\n\n\n$$\nZ = \\frac{X-\\mu}{\\sigma} \\sim N(0,1)\n$$\n\n### $N(\\mu, \\sigma^2)$\n\n$$\nZ \\sim N(0,1)\n$$\n\n$$\nX = Z\\sigma + \\mu \\sim N(\\mu, \\sigma^2)\n$$\n\n### $\\chi^2(1)$\n\n$$\nZ \\sim N(0,1)\n$$\n\n$$\nZ^2 \\sim \\chi^2(1)\n$$\n\n### $F(m,n)$\n\n$$\nU \\sim \\chi^2(m)\n$$\n\n$$\nV \\sim \\chi^2(n)\n$$\n\n$$\nF = \\frac{U/m}{V/n} \\sim F(m,n)\n$$\n\n### $t(n)$\n\n$$\nZ \\sim N(0,1)\n$$\n\n\n$$\nU \\sim \\chi^2(m)\n$$\n\n$$\nT = \\frac{Z}{\\sqrt{U/m}} \\sim t(n)\n$$\n\n### $Beta(\\alpha, \\beta)$\n\n$$\nU \\sim Gamma(\\alpha,\\lambda)\n$$\n\n$$\nV \\sim Gamma(\\beta,\\lambda)\n$$\n\n$$\nX = \\frac{U}{U+V} \\sim Beta(\\alpha,\\beta)\n$$\n\n\n## Monte Carlo Integration\n\nMonte Carlo Integration is a numerical technique to compute a numerical of an integral.\n\nIt relies on simulating from a know distribution to obtain the expected value of a desired function.\n\n### Integration\n\nIntegration is commonly used to find the area under a curve.\n\n### Expectation\n\nLet $X$ be a continuous random variable:\n\n$$\nE(X) = \\int_{X}xf(x)dx \n$$\n\n$$\nE\\{g(X)\\} = \\int_Xg(x)f(x)dx\n$$\n\n\n### Strong Law of Large Numbers\n\nAs $n\\rightarrow \\infty$ (ie simulate a large number of random variables):\n\n$$\n\\bar X_n \\rightarrow E_f(X)\n$$\n\nwhere\n\n$$\n\\bar X_n \\rightarrow = \\frac{1}{n}\\sum^n_{i=1}X_i\n$$\n\n### Strong Law of Large Numbers\n\n$$\n\\bar X_n^{(g)} \\rightarrow E_f\\{g(X)\\}\n$$\n\nwhere\n\n$$\n\\bar X_n^{(g)} \\rightarrow = \\frac{1}{n}\\sum^n_{i=1}g(X_i)\n$$\n\n### The Expected Value of a Normal Distribution\n\n$$\nE(X) = \\int^{\\infty}_{-\\infty}\\frac{x}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{(x-\\mu)^2}{\\sigma^2}\\right\\} dx = \\mu\n$$\n\n### Variance of a Normal Distribution\n\n$$\nVar(X) = E[\\{X-E(X)\\}^2] \\\\= \\int^{\\infty}_{-\\infty}\\frac{\\{x-E(X)\\}^2}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{(x-\\mu)^2}{\\sigma^2}\\right\\} dx = \\sigma^2\n$$\n\n### Using Monte Carlo Integration to obtain expectations\n\n1. Simulate from a target distribution $f$\n2. Calculate the mean for the expected value\n\n\n### Using Monte Carlo Integration\n\n$$\nX \\sim N(\\mu, \\sigma^2)\n$$\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rnorm(100000, mean = -2, sd = 3)\nmean(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] -1.987084\n```\n\n\n:::\n\n```{.r .cell-code}\nvar(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 8.98884\n```\n\n\n:::\n:::\n\n\n\n\n\n### Gamma Distrbution\n\n$$\nX \\sim Gamma(3,4)\n$$\n\n### Beta Distribution\n\n$$\nX \\sim Beta(2,3)\n$$\n\n### $\\chi^2(p)$\n\n$$\nX \\sim \\chi^2(39)\n$$ \n\n### Finding the Probability\n\nIntegration is commonly used to determine the probability of observing a certain range of values for a continuous random variable.\n\n$$\nP(a < X < b)\n$$\n\n### Graphical Setting\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(-4, 4, length.out = 1000)\ndt_two<-function(x){\n            y <- dnorm(x)\n            y[x< -1 | x>2] <-NA\n            return(y)\n        }\nx |> (\\(.) tibble(x = ., y = dnorm(.)))() |> \n  ggplot(aes(x, y)) +\n    geom_line() +\n    stat_function(fun = dt_two, geom = \"area\", fill = \"green\") + \n    theme_bw()\n```\n\n::: {.cell-output-display}\n![](mc_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n\n### Finding the Propbabilities of a Random Variable\n\nFor a given random variable $X$, finding the probability is the same as\n\n$$\nE\\{I(a<X<b)\\} = \\int_X I(a<X<b) f(x) dx\n$$\n\nwhere $I(a<X<b)$ is the indicator function.\n\n### Indicator Function\n\n$$\nI(a<X<b) = \\left\\{\\begin{array}{cc}\n1 & a<X<b\\\\\n0 & \\mathrm{otherwise}\n\\end{array}\n\\right.\n$$\n\n### Finding the Probability\n\n$$\n\\begin{align}\nE\\{I(a<X<b)\\} &  = \\int_X I(a<X<b) f(x) dx\\\\ \n & = \\int_a^b f(x) dx\\\\\n & = P(a < X < b)\n\\end{align}\n$$\n\n### Monte Carlo Probability\n\n1. Simulate from a target distribution $f$\n2. Calculate the mean for $I(a<X<b)$\n\n### Normal RV Example\n\nLet $X\\sim N(4, 2)$, find $P(3 < X < 6)$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\npnorm(6, 4, sqrt(2)) -  pnorm(3, 4, sqrt(2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.6816003\n```\n\n\n:::\n:::\n\n\n\n\n### Using Monte Carlo Methods\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nx <- rnorm(1000000, 4, sqrt(2))\nmean((x > 3 & x < 6))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.681979\n```\n\n\n:::\n:::\n\n\n\n\n\n### Logistic RV Example\n\nLet $X\\sim Logistic(3, 5)$, find $P(-1 < X < 5)$\n\n\n### Weibull RV Example\n\nLet $X\\sim Weibull(1, 1)$, find $P(2 < X < 5.5)$\n\n\n### F RV Example\n\nLet $X\\sim F(2, 45)$, find $P(1 < X < 3)$\n\n\n### Monte Carlo Integration\n\nMonte Carlo Integration can be used to evaluate finite-bounded integrals of the following form:\n\n$$\n\\int^b_a g(x) dx\n$$\nsuch that $-\\infty <a,b<\\infty$.\n\n### Monte Carlo Example Integration\n\n$$\n\\int^1_{0} \\{\\cos(50x) - sin(20x)\\}^2dx\n$$\n\n## Monte Carlo Example Integration\n#\nLet $X \\sim U(0,1)$ with $f(x) = 1$, then\n\n$$\nE[\\{\\cos(50x) - sin(20x)\\}^2] =\\int^1_{0} \\{\\cos(50x) - sin(20x)\\}^2dx\n$$\n\n### Using Numerical Integration\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nff <- function(x){\n  (cos(50*x)-sin(50*x))^2\n}\nintegrate(ff,0,1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 0.9986232 with absolute error < 9.5e-11\n```\n\n\n:::\n:::\n\n\n\n\n\n### Monte Carlo Example Integration\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- runif(10000000, 0, 1)\nmean((cos(50*x)-sin(50*x))^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9985457\n```\n\n\n:::\n:::\n\n\n\n\n\n### Monte Carlo Example Integration\n\n$$\n\\int^{15}_{10} \\{\\cos(50x) - sin(20x)\\}^2dx\n$$\n\n### Monte Carlo Integration\n\nLet $X \\sim U(10,15)$ with $f(x) = 1$, then\n\n$$\nE[\\{\\cos(50x) - sin(20x)\\}^2] = \\\\\n\\int^{15}_{10} \\frac{1}{5} \\{\\cos(50x) - sin(20x)\\}^2dx\n$$\n\n### Monte Carlo Example Integration\n\n$$\n\\int^{15}_{10} \\{\\cos(50x) - sin(20x)\\}^2dx = \\\\\n5 * E[\\{\\cos(50x) - sin(20x)\\}^2]\n$$\n\n### Monte Carlo Example Integration\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nff <- function(x){\n  (cos(50*x)-sin(50*x))^2\n}\nintegrate(ff,10,15)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 4.993274 with absolute error < 1.1e-06\n```\n\n\n:::\n:::\n\n\n\n\n### Monte Carlo Example Integration\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nx <- runif(10000000, 10, 15)\nmean(ff(x)) * 5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 4.993028\n```\n\n\n:::\n:::\n\n\n\n\n### Monte Carlo Integration Algorithm\n\nGiven: \n$$\n\\int_a^b g(x) dx\n$$\n\n1.    Simulate $n$ value from $X \\sim U(a,b)$\n2.    Take the average, $\\frac{1}{n}\\sum^{n}_{i=1}g(x_i)$\n3.    Multiply the average by $b-a$: $\\frac{b-a}{n}\\sum^{n}_{i=1}g(x_i)$\n\n### MC Examples\n\n$$\n\\int_0^{2}  e^{-x^2/2} dx\n$$\n\n\n## Importance Sampling\n\nImportance sampling is an extension of Monte Carlo integration where it addresses the limitations of large variance of the expected value and the bounds required in integrals.\n\nThis is done by simulating from a random variable that has an infinite support system.\n\nLet's say we are interested in finding the numerical value of the following integral:\n\n$$\n\\int_{-\\infty}^\\infty g(x) dx\n$$\n\n\nIf we view the integral as an expectation of an easily simulated random variable, we can compute the numerical value.\n\nLet $X$ be a random variable $f$, then\n\n$$\n\\int_{-\\infty}^\\infty g(x) dx = \\int_{-\\infty}^\\infty \\frac{g(x)}{f(x)} f(x) dx = E\\left\\{\\frac{g(x)}{f(x)}\\right\\}\n$$\n\n\nSince the integral is the expectation of $X$, it can be obtained by taking the mean of the simulated values applied to $g(x)/f(x)$.\n\n### Example\n\n$$\n\\int_{-\\infty}^{\\infty}  e^{-x^2/2} dx\n$$\n\n### Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rt(1000000, df = 1)\nf2 <- function(x){\n  exp(-x^2/2) / dt(x, 1)\n}\nmean(f2(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 2.506146\n```\n\n\n:::\n\n```{.r .cell-code}\nsqrt(2*pi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 2.506628\n```\n\n\n:::\n:::\n\n\n\n\n\n### Choosing $f(x)$\n\nChoose a value $f(x)$ that follows a shape close enough to $g(x)$ that has the same bounds as the integral.\n",
    "supporting": [
      "mc_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}